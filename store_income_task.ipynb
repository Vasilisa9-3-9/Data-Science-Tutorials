{"cells":[{"cell_type":"markdown","metadata":{"id":"lqt_yzRy16Wj"},"source":["## Compulsory Task \n","\n","In this compulsory task you will clean the country column and parse the date column in the **store_income_data_task.csv** file."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"vBP3WN2O16Wp"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/Caskroom/miniforge/base/lib/python3.10/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n","  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>store_name</th>\n","      <th>store_email</th>\n","      <th>department</th>\n","      <th>income</th>\n","      <th>date_measured</th>\n","      <th>country</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>Cullen/Frost Bankers, Inc.</td>\n","      <td></td>\n","      <td>Clothing</td>\n","      <td>$54438554.24</td>\n","      <td>4-2-2006</td>\n","      <td>United States/</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Nordson Corporation</td>\n","      <td></td>\n","      <td>Tools</td>\n","      <td>$41744177.01</td>\n","      <td>4-1-2006</td>\n","      <td>Britain</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Stag Industrial, Inc.</td>\n","      <td></td>\n","      <td>Beauty</td>\n","      <td>$36152340.34</td>\n","      <td>12-9-2003</td>\n","      <td>United States</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>FIRST REPUBLIC BANK</td>\n","      <td>ecanadine3@fc2.com</td>\n","      <td>Automotive</td>\n","      <td>$8928350.04</td>\n","      <td>8-5-2006</td>\n","      <td>Britain/</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Mercantile Bank Corporation</td>\n","      <td></td>\n","      <td>Baby</td>\n","      <td>$33552742.32</td>\n","      <td>21-1-1973</td>\n","      <td>United Kingdom</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     store_name         store_email  department        income  \\\n","id                                                                              \n","1    Cullen/Frost Bankers, Inc.                        Clothing  $54438554.24   \n","2           Nordson Corporation                           Tools  $41744177.01   \n","3         Stag Industrial, Inc.                          Beauty  $36152340.34   \n","4           FIRST REPUBLIC BANK  ecanadine3@fc2.com  Automotive   $8928350.04   \n","5   Mercantile Bank Corporation                            Baby  $33552742.32   \n","\n","   date_measured          country  \n","id                                 \n","1       4-2-2006   United States/  \n","2       4-1-2006          Britain  \n","3      12-9-2003    United States  \n","4       8-5-2006         Britain/  \n","5      21-1-1973   United Kingdom  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["#Load the libraries \n","import pandas as pd\n","import numpy as np\n","import fuzzywuzzy\n","from fuzzywuzzy import process\n","import chardet\n","\n","\n","#Load up store_income_dat_task.csv\n","df = pd.read_csv(\"store_income_data_task.csv\", index_col = 0, keep_default_na = False) \n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"ItqLwumA16Wr"},"source":["1. Take a look at all the unique values in the \"country\" column. Then, convert the column to lowercase and remove any trailing white spaces."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"sLkzt4Hr16Wr"},"outputs":[{"name":"stdout","output_type":"stream","text":["There are 77 unique countries\n"]},{"data":{"text/plain":["id\n","1                  united states\n","2                        britain\n","3                  united states\n","4                        britain\n","5                 united kingdom\n","                  ...           \n","996        s. africasouth africa\n","997                united states\n","998     united states of america\n","999                      england\n","1000              united kingdom\n","Name: country, Length: 914, dtype: object"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["countries = df['country'].unique()\n","print(f\"There are {len(countries)} unique countries\")\n","\n","#remove white spaces and make all the letters lower case \n","df['country'] = df['country'].str.lower()\n","df['country'] = df['country'].str.strip()\n","df['country'] = df['country'].str.strip(\".\")\n","df['country'] = df['country'].str.strip(\"/\")\n","\n","#remove any emptry values \n","df = df[df['country']!= \"\"]\n","\n","#print the unique countries after modifications \n","df['country']\n"]},{"cell_type":"markdown","metadata":{"id":"P6dcDc4P16Ws"},"source":["2. Note that there should only be three separate countries. Eliminate all variations, so that 'South Africa', 'United Kingdom' and 'United States' are the only three countries."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"qeV3CxMR16Ws"},"outputs":[{"name":"stdout","output_type":"stream","text":["done!\n","done!\n","done!\n","done!\n","done!\n","There are 3 unique countries\n"]},{"data":{"text/plain":["array(['united states', 'united kingdom', 'south africa'], dtype=object)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["#create a function that will help replace any repeats within the country names \n","def replace_matches_in_column(df, column, string_to_match, min_ratio = 90):\n","    #get a list of unique strings\n","    strings = df[column].unique()\n","\n","    #get the top 10 closest matches to our input string\n","    matches = fuzzywuzzy.process.extract(string_to_match, strings, \n","                                         limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n","    \n","    #only get matches with a ratio > 90\n","    close_matches = [matches[0] for matches in matches if matches[1] >= min_ratio]\n","\n","    #get the rows of all the close matches in our dataframe\n","    rows_with_matches = df[column].isin(close_matches)\n","\n","    #replace all rows with close matches with the input matches \n","    df.loc[rows_with_matches, column] = string_to_match\n","\n","    #print done, to identify that the function has been carried out \n","    print(\"done!\")\n","\n","replace_matches_in_column(df= df, column='country', string_to_match=\"united kingdom\")\n","replace_matches_in_column(df= df, column='country', string_to_match=\"uk\")\n","replace_matches_in_column(df= df, column='country', string_to_match=\"united states\")\n","replace_matches_in_column(df= df, column='country', string_to_match=\"united states of america\")\n","replace_matches_in_column(df= df, column='country', string_to_match=\"s. africasouth africa\")\n","\n","#replace any names that represnt the same country with one consistent name choice, to avoid any repeats \n","df.replace('uk', 'united kingdom', inplace=True)\n","df.replace('u.k.', 'united kingdom', inplace=True)\n","df.replace('u.k', 'united kingdom', inplace=True)\n","df.replace('britain', 'united kingdom', inplace=True)\n","df.replace('england', 'united kingdom', inplace=True)\n","df.replace('united states of america', 'united states', inplace=True)\n","df.replace('america', 'united states', inplace=True)\n","df.replace('sa', 'south africa', inplace=True)\n","df.replace('s.a.', 'south africa', inplace=True)\n","df.replace('s. africasouth africa', 'south africa', inplace=True)\n","df.replace('s.a', 'south africa', inplace=True)\n","\n","#print out the unique countries left \n","countries = df['country'].unique()\n","\n","print(f\"There are {len(countries)} unique countries\")\n","countries\n"]},{"cell_type":"markdown","metadata":{"id":"UJZDMTwP16Ws"},"source":["3. Create a new column called `days_ago` in the DataFrame that is a copy of the 'date_measured' column but instead it is a number that shows how many days ago it was measured from the current date. Note that the current date can be obtained using `datetime.date.today()`."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"gMJbN84P16Wt"},"outputs":[{"data":{"text/plain":["id\n","1       6273 days\n","2       6304 days\n","3       7149 days\n","4       6180 days\n","5      18340 days\n","          ...    \n","996     6393 days\n","997    11799 days\n","998     5097 days\n","999     4469 days\n","1000    4147 days\n","Name: days_ago, Length: 914, dtype: timedelta64[ns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["#import the datetime library \n","import datetime \n","\n","#create a specific format upon obtaining the today's date\n","today = \"{dt.day}-{dt.month}-{dt.year}\".format(dt = datetime.datetime.now())\n","\n","#identify the \"date_measured\" data from the csv document \n","date_measured = df['date_measured']\n","\n","#identify both dates as a \"date\" format \n","date_obj_1 = pd.to_datetime(today)\n","date_obj_2 = pd.to_datetime(date_measured, format = \"%d-%m-%Y\")\n","\n","#subtract the dates from each other to get the \"days_ago\" column \n","df[\"days_ago\"] = date_obj_1 - date_obj_2\n","df[\"days_ago\"]\n","\n","\n","\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.10.0 ('phd')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"vscode":{"interpreter":{"hash":"63d17dc58a06b6a6d4136fb13c245dafcf53668da37b1c3052c24d689135f5bb"}}},"nbformat":4,"nbformat_minor":0}
